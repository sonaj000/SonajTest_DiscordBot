{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #parent object of nn models\n",
    "import torch.nn.functional as F #activation function\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how we will feed in the training data \n",
    "\"\"\"NLP techiques \n",
    "1. first tokenize the sentence which will split a sentence into individual units such as words and punctuation\n",
    "2. lower the words so not capitalize and apply stemming which is technique that aims to crudely chop off ends of words like organizer and organizes is organ\n",
    "3. then we calculate bag of words which is put 0 and 1 for each word in the sentence in pre existing bag of words \"\"\"\n",
    "from turtle import forward\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes) -> None:\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size,num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        #w\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6246b25e200e4c5124e3e61789ac81350562f0761bbcf92ad9e48654207659c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
